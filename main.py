import streamlit as st
import pandas as pd
import numpy as np
import joblib
from urllib.parse import urlparse, parse_qs
from googleapiclient.discovery import build
from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
import matplotlib

# í•œê¸€ í°íŠ¸ ì„¤ì •
matplotlib.rcParams['font.family'] = 'Malgun Gothic'  # ìœˆë„ìš°
# matplotlib.rcParams['font.family'] = 'AppleGothic'  # Mac
matplotlib.rcParams['axes.unicode_minus'] = False

# YouTube API ì„¤ì •
API_KEY = "AIzaSyBKxUeZ41w7jBpj9GzKv0emNM7_4-V1e4Q"
youtube = build('youtube', 'v3', developerKey=API_KEY)

st.set_page_config(page_title="YouTube ëŒ“ê¸€ ê°ì • ë¶„ì„", layout="wide")
st.title("ğŸ¥ YouTube ëŒ“ê¸€ ê°ì • ë¶„ì„ê¸°")

# ìœ íŠœë¸Œ ë§í¬ ì…ë ¥
url = st.text_input("YouTube ì˜ìƒ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

# ì˜ìƒ ID ì¶”ì¶œ í•¨ìˆ˜
def extract_video_id(url):
    query = urlparse(url)
    if query.hostname == 'youtu.be':
        return query.path[1:]
    if query.hostname in ('www.youtube.com', 'youtube.com'):
        return parse_qs(query.query).get('v', [None])[0]
    return None

# ëŒ“ê¸€ ìˆ˜ì§‘ í•¨ìˆ˜
def get_comments(video_id):
    comments = []
    response = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=100,
        textFormat="plainText"
    ).execute()
    for item in response['items']:
        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
        comments.append(comment)
    return comments

# ì¢‹ì•„ìš”/ì‹«ì–´ìš” ë¹„ìœ¨ ì‹œê°í™” í•¨ìˆ˜
def get_video_stats(video_id):
    response = youtube.videos().list(
        part='statistics',
        id=video_id
    ).execute()
    stats = response['items'][0]['statistics']
    like = int(stats.get('likeCount', 0))
    dislike = 0  # YouTube APIëŠ” dislikeë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ (ì •ì±… ë³€ê²½)
    return like, dislike

# ê°ì • ë¶„ì„ í•¨ìˆ˜ (ëª¨ë¸ ì‚¬ìš©)
def predict_sentiment(comments):
    vectorizer = joblib.load("model/vectorizer.pkl")
    model = joblib.load("model/sentiment_model.pkl")
    X = vectorizer.transform(comments)
    return model.predict(X)

# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜
def create_wordcloud(texts, title):
    text = ' '.join(texts)
    wordcloud = WordCloud(font_path='fonts/malgun.ttf', background_color='white', width=800, height=400).generate(text)
    fig, ax = plt.subplots()
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.subheader(title)
    st.pyplot(fig)

# ë„ë„› ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
def plot_donut(sentiments):
    df = pd.DataFrame(sentiments, columns=['label'])
    value_counts = df['label'].value_counts().reset_index()
    value_counts.columns = ['ê°ì •', 'ìˆ˜']
    fig = px.pie(value_counts, names='ê°ì •', values='ìˆ˜', hole=0.5, title='ê¸ì •/ë¶€ì • ê°ì • ë¹„ìœ¨')
    st.plotly_chart(fig)

# ë³¸ë¬¸ ì‹¤í–‰
if url:
    video_id = extract_video_id(url)
    if video_id:
        comments = get_comments(video_id)
        like, dislike = get_video_stats(video_id)

        # ì¢‹ì•„ìš” ì‹œê°í™”
        st.subheader("ğŸ‘ ì¢‹ì•„ìš” ìˆ˜ ì‹œê°í™”")
        fig = px.pie(names=["ì¢‹ì•„ìš”", "ì‹«ì–´ìš”(ì¶”ì •ì¹˜)"], values=[like, 1], hole=0.4)
        st.plotly_chart(fig)

        # ê°ì • ë¶„ì„
        sentiments = predict_sentiment(comments)

        # ê¸ì •/ë¶€ì • ì›Œë“œí´ë¼ìš°ë“œ
        positive_comments = [c for c, s in zip(comments, sentiments) if s == 'positive']
        negative_comments = [c for c, s in zip(comments, sentiments) if s == 'negative']

        create_wordcloud(positive_comments, "ğŸ˜Š ê¸ì • ëŒ“ê¸€ ì›Œë“œí´ë¼ìš°ë“œ")
        create_wordcloud(negative_comments, "ğŸ˜  ë¶€ì • ëŒ“ê¸€ ì›Œë“œí´ë¼ìš°ë“œ")

        # ì „ì²´ ì›Œë“œí´ë¼ìš°ë“œ
        create_wordcloud(comments, "ğŸ’¬ ì „ì²´ ëŒ“ê¸€ ì›Œë“œí´ë¼ìš°ë“œ")

        # ê°ì • ë„ë„› ì°¨íŠ¸
        plot_donut(sentiments)
    else:
        st.error("ì˜¬ë°”ë¥¸ ìœ íŠœë¸Œ ë§í¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
